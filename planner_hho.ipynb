{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "\n",
    "client = OpenAI(api_key=keys.api)\n",
    "\n",
    "# Define the tools for RAG and human handover with logic embedded in descriptions\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \n",
    "        'function': {\n",
    "            'name\": \"query_knowledge_base\",\n",
    "            \"description\": \"Query the knowledge base to get answers to customer questions about specific topics and issues. This should be the first approach to solving customer issues before considering a handover to a human agent. Use this function to address the customer's question when sufficient information is provided or can be inferred.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"topic\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The last relevant topic of the question (e.g., 'billing', 'account', 'product features', 'technical issue') extracted from conversation history\"\n",
    "                    },\n",
    "                    \"issue\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"A last relevant description of the customer's issue or question extracted from conversation history\"\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"topic\", \"issue\"],\n",
    "                \"additionalProperties\": False\n",
    "            },\n",
    "            \"strict\": True\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"handover_to_agent\",\n",
    "            \"description\": \"\"\"Transfer the conversation to a human customer support agent. This function should ONLY be used in specific circumstances. Use this function ONLY IF: \n",
    "            1) the system didn't already provide an answer to the customer question using a knowledge base. OR the customer appears frustrated (all caps, exclamation marks, etc.)... one of those 2 conditions\n",
    "            AND\n",
    "            2) the customer requests human intervention\"\"\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"topic\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The last relevant topic of the question (e.g., 'billing', 'account', 'product features', 'technical issue') extracted from conversation history\"\n",
    "                    },\n",
    "                    \"issue\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"A last relevant description of the customer's issue or question extracted from conversation history\"\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"topic\", \"issue\"],\n",
    "                \"additionalProperties\": False\n",
    "            },\n",
    "            \"strict\": True\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# Generic system prompt without specific function logic\n",
    "system_prompt = \"\"\"You are a helpful customer support AI assistant. Your goal is to assist customers with their inquiries efficiently and effectively. You have access to tools that can help you best serve the customer. Use these tools appropriately based on their descriptions and the customer's needs.\"\"\"\n",
    "\n",
    "# Initialize variables to track conversation and function usage\n",
    "conversation_history = []\n",
    "rag_function_used = False\n",
    "hho_function_used = False\n",
    "\n",
    "def handle_customer_message(user_message):\n",
    "    \"\"\"Process a customer message and return the appropriate response\"\"\"\n",
    "    global conversation_history, rag_function_used, hho_function_used\n",
    "    \n",
    "    # Add user message to conversation history\n",
    "    conversation_history.append({\"role\": \"user\", \"content\": user_message})\n",
    "    \n",
    "    # Prepare messages for API call, including full conversation history\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "    \n",
    "    # Add all previous conversation messages\n",
    "    messages.extend(conversation_history)\n",
    "    \n",
    "    # Make the API call\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=messages,\n",
    "        tools=tools\n",
    "    )\n",
    "    \n",
    "    # Get assistant's response\n",
    "    assistant_message = completion.choices[0].message\n",
    "    \n",
    "    # Store this message format for history\n",
    "    history_message = {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": assistant_message.content if assistant_message.content else None\n",
    "    }\n",
    "    \n",
    "    # Process and display the result\n",
    "    if hasattr(assistant_message, 'tool_calls') and assistant_message.tool_calls:\n",
    "        # Add tool calls to the history message\n",
    "        history_message[\"tool_calls\"] = []\n",
    "        \n",
    "        for tool_call in assistant_message.tool_calls:\n",
    "            # Add to history\n",
    "            tool_call_dict = {\n",
    "                \"id\": tool_call.id,\n",
    "                \"type\": tool_call.type,\n",
    "                \"function\": {\n",
    "                    \"name\": tool_call.function.name,\n",
    "                    \"arguments\": tool_call.function.arguments\n",
    "                }\n",
    "            }\n",
    "            history_message[\"tool_calls\"].append(tool_call_dict)\n",
    "            \n",
    "            print(f\"INTERNAL PROCESSING: Function called - {tool_call.function.name}\")\n",
    "            print(f\"Arguments: {tool_call.function.arguments}\")\n",
    "            \n",
    "            # Execute the appropriate function based on what was called\n",
    "            if tool_call.function.name == \"query_knowledge_base\":\n",
    "                # Mark that RAG has been used\n",
    "                rag_function_used = True\n",
    "                \n",
    "                # Parse arguments\n",
    "                args = json.loads(tool_call.function.arguments)\n",
    "                \n",
    "                # Simulating RAG response\n",
    "                result = f\"Knowledge base result for topic: {args['topic']} and issue: {args['issue']}\"\n",
    "                \n",
    "                # Create function response\n",
    "                function_response = {\n",
    "                    \"role\": \"tool\",\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"content\": result\n",
    "                }\n",
    "                \n",
    "                # Add function response to conversation history\n",
    "                conversation_history.append(history_message)\n",
    "                conversation_history.append(function_response)\n",
    "                \n",
    "                # Get final response from model\n",
    "                final_messages = messages.copy()\n",
    "                final_messages.append(assistant_message)\n",
    "                final_messages.append(function_response)\n",
    "                \n",
    "                final_response = client.chat.completions.create(\n",
    "                    model=\"gpt-4o\",\n",
    "                    messages=final_messages\n",
    "                )\n",
    "                \n",
    "                # Add final response to conversation history\n",
    "                final_message = {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": final_response.choices[0].message.content\n",
    "                }\n",
    "                conversation_history.append(final_message)\n",
    "                \n",
    "                # print(\"\\nFinal response to user:\")\n",
    "                print(final_response.choices[0].message.content)\n",
    "                return final_response.choices[0].message.content\n",
    "                \n",
    "            elif tool_call.function.name == \"handover_to_agent\":\n",
    "                \n",
    "                hho_function_used = True\n",
    "                # Here you would implement the actual agent handover functionality\n",
    "                args = json.loads(tool_call.function.arguments)\n",
    "                \n",
    "                # Create function response\n",
    "                function_response = {\n",
    "                    \"role\": \"tool\",\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"content\": \"Human agent connected.\"\n",
    "                }\n",
    "                \n",
    "                # Add messages to conversation history\n",
    "                conversation_history.append(history_message)\n",
    "                conversation_history.append(function_response)\n",
    "                \n",
    "                \n",
    "                handover_message = \"You're being connected to a human agent. Please wait a moment.\"\n",
    "                \n",
    "                # Add final handover message to history\n",
    "                conversation_history.append({\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": handover_message\n",
    "                })\n",
    "                \n",
    "                return handover_message\n",
    "    else:\n",
    "        # No function calls, just a direct response\n",
    "        conversation_history.append(history_message)\n",
    "        print(\"\\nINTERNAL PROCESSING: Disambiguation\")\n",
    "        #print(assistant_message.content)\n",
    "        return assistant_message.content\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to interact with the customer support system\"\"\"\n",
    "    global conversation_history, rag_function_used, hho_function_used\n",
    "    \n",
    "    print(\"Customer Support System\")\n",
    "    print(\"Type 'exit' to end the conversation\")\n",
    "    print(\"----------------------------------\")\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"\\nCustomer: \")\n",
    "        \n",
    "        if user_input.lower() == 'exit':\n",
    "            print(\"Conversation ended.\")\n",
    "            break\n",
    "        \n",
    "        print(f\"User: {user_input}\")\n",
    "        response = handle_customer_message(user_input)\n",
    "        print(f\"AI: {response}\")\n",
    "        \n",
    "        print(\"--------------Turn End------------\")\n",
    "        \n",
    "        # Debug information\n",
    "        # print(\"\\n[Debug] RAG function used:\", rag_function_used)\n",
    "        # print(\"[Debug] HHO function used:\", hho_function_used,\"\\n\")\n",
    "\n",
    "    # Print full conversation history\n",
    "    print(\"\\nFull conversation history:\")\n",
    "    for msg in conversation_history:\n",
    "        if msg.get(\"role\") == \"user\":\n",
    "            print(f\"Customer: {msg['content']}\")\n",
    "        elif msg.get(\"role\") == \"assistant\" and msg.get(\"content\"):\n",
    "            print(f\"AI: {msg['content']}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import helper as hlp\n",
    "\n",
    "# Load all configurations\n",
    "configs = hlp.load_all_configs()\n",
    "\n",
    "# Access individual configs\n",
    "planner_config = configs[\"planner\"]\n",
    "user_data = configs[\"user_data\"]  # This is the parsed user_json as a dict\n",
    "tools = configs[\"tools\"]\n",
    "content_items = configs[\"content\"][\"items\"]\n",
    "\n",
    "# Use the configuration data...\n",
    "planner_mode = planner_config.get(\"mode\", \"fast\")\n",
    "combined_result = hlp.generate_schema_for_tools(tools)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    # Process the tools with combined schema\n",
    "\n",
    "\n",
    "print(planner_mode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toolz = [\n",
    "    {\n",
    "        \"TaxToolz\": {\n",
    "            \"region2\": \"US\",\n",
    "            \"relevance_score\": 85\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"Untitled Tool\": {\n",
    "            \"relevance_score\": 25\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
